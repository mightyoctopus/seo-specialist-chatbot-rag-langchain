{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0b4181c-7619-49e0-9b01-0d7382f61f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q python-dotenv gradio langchain langchain-community langchain-openai langchain-chroma chromadb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4903b197-c571-439c-8540-cd2be45dfae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "### Google Drive Auth Related Installation \n",
    "!pip install -q --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5439be99-5af1-4154-bf2c-fa8909bbd956",
   "metadata": {},
   "source": [
    "## Google Docs API (Fetching Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6b06c6d-e93f-44e7-bada-89a44f6d0eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from typing import List\n",
    "\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3afb10f6-ff56-44a1-83d7-3a63942e4398",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_PATH = \"secrets/token.json\" \n",
    "CREDENTIALS_PATH = \"secrets/credentials.json\"\n",
    "\n",
    "SCOPES = [\n",
    "    \"https://www.googleapis.com/auth/drive.readonly\",\n",
    "    \"https://www.googleapis.com/auth/documents.readonly\",\n",
    "]\n",
    "\n",
    "### Original One: \n",
    "INITIAL_FILEID = \"1xWRgZ4c6BhBV97WniRY5vIWTyGlQSMljjXggKt3jfIY\"\n",
    "TECHNICAL_SEO_FILEID = \"1HGt1K9AbFz1GwY6jzQiVGmqZwgP6zHPwDotGD1d8bHU\" \n",
    "CONTENT_WRITING_FILEID = \"1IdSXZwKeMo4su80s3sn4iSEQ18pvXDBsFW_uobj4zBQ\"\n",
    "CONTENT_MARKETING_FILEID = \"11QfPGe2XY57RL764FoeN68lI1LvjOdwOM5pDaxyC3O8\"\n",
    "LOCAL_SEO_FILEID = \"1uc4qH5roh6_xzv5x4osZG7nrPHpPUqRz9qPn31Y1azY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ed87df8-6b6b-42f6-9be2-1587418a02d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "creds = None\n",
    "\n",
    "### Google Drive Authentication\n",
    "def auth_google_docs():\n",
    "    global creds\n",
    "    if os.path.exists(TOKEN_PATH):\n",
    "        creds = Credentials.from_authorized_user_file(TOKEN_PATH, SCOPES)\n",
    "\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token: \n",
    "            creds.refresh(Request())\n",
    "        else: \n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                CREDENTIALS_PATH, SCOPES\n",
    "            )\n",
    "            creds = flow.run_local_server(port=8080, open_browser=False)\n",
    "\n",
    "        #Save the credentials\n",
    "        with open(TOKEN_PATH, \"w\") as token:\n",
    "            token.write(creds.to_json())\n",
    "\n",
    "    return creds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6abae530-74ca-4580-aed9-f11a99d1c221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_docs_text() -> List[Document]:\n",
    "    creds = auth_google_docs()\n",
    "    ### Build Google Docs Service\n",
    "    service = build(\"docs\", \"v1\", credentials=creds)\n",
    "\n",
    "    doc_ids = [ \n",
    "        INITIAL_FILEID, TECHNICAL_SEO_FILEID, CONTENT_WRITING_FILEID,\n",
    "        CONTENT_MARKETING_FILEID, LOCAL_SEO_FILEID\n",
    "    ]\n",
    "\n",
    "    docs = []\n",
    "    \n",
    "    for doc_id in doc_ids: \n",
    "        try: \n",
    "            doc = service.documents().get(documentId=doc_id).execute()\n",
    "            title = doc[\"title\"]\n",
    "            elements = doc[\"body\"][\"content\"]\n",
    "\n",
    "            text = \"\" \n",
    "            for elem in elements: \n",
    "                if \"paragraph\" in elem: \n",
    "                    for run in elem[\"paragraph\"][\"elements\"]:\n",
    "                        if \"textRun\" in run: \n",
    "                            text += run[\"textRun\"][\"content\"]\n",
    "\n",
    "            ### Pydantic Document for each doc\n",
    "            docs.append(\n",
    "                Document(\n",
    "                    page_content=text, \n",
    "                    metadata={\"title\": title, \"id\": doc_id}\n",
    "                )\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"{doc_id} not found: {e}\")\n",
    "\n",
    "        \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be1d6c1-24af-4a8d-bec2-c6e766d6f8f0",
   "metadata": {},
   "source": [
    "## Langchain LCEL (RAG) Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cfcfe54-27b9-4efc-b87c-82072424861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LangChain, RAG\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import Document \n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain_core.output_parsers import StrOutputParser \n",
    "from langchain.schema.runnable import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "481f809b-3e2f-435d-b22e-bb2304fcd0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d78231c5-0fc4-417e-9a8b-ed2ae59d8275",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_MODEL_ID =\"gpt-5-mini\"\n",
    "db_path = \"vector_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbe843dc-a35a-4fae-ad0e-012af85a73e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "print(OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "865c2475-4b13-488c-8169-ee96eb9221f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Docs:  5\n"
     ]
    }
   ],
   "source": [
    "def load_docs() -> List[Document]: \n",
    "    docs: List[Document] = get_docs_text() \n",
    "    return docs\n",
    "\n",
    "print(\"Number of Docs: \", len(load_docs()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53c8916e-2902-4ffa-ab84-c61329c9d145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(): \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=800, chunk_overlap=100, \n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    "    )\n",
    "    return text_splitter.split_documents(load_docs())\n",
    "\n",
    "### Sanity check: \n",
    "# chunks = split_text()\n",
    "# print(f\"Total Chunks: {len(chunks)}\")\n",
    "\n",
    "# for c in chunks[:10]: \n",
    "#     print(f\"Meta: {c.metadata} | LENGTH: {len(c.page_content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d20fef8-a3ee-4264-96ff-ec000a1a1cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded Text:  <langchain_chroma.vectorstores.Chroma object at 0x10f8e97f0>\n"
     ]
    }
   ],
   "source": [
    "def vectorize_text(batch_size: int = 100):\n",
    "    embeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY)\n",
    "    all_docs: List[Document] = split_text()\n",
    "\n",
    "    vector_store = None\n",
    "    for i in range(0, len(all_docs), batch_size): \n",
    "        batch = all_docs[i:i+batch_size]\n",
    "        if vector_store is None: \n",
    "            vector_store = Chroma.from_documents(\n",
    "                documents=batch, \n",
    "                embedding=embeddings, \n",
    "                persist_directory=db_path\n",
    "            )\n",
    "        else: \n",
    "            vector_store.add_documents(batch)\n",
    "    return vector_store\n",
    "\n",
    "print(\"Embedded Text: \", vectorize_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab06007e-584f-4657-9e48-74c349dc96d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt() -> ChatPromptTemplate: \n",
    "    \n",
    "    system_template = \"\"\"You are a top-tier SEO strategist helping with small business SEO. \n",
    "    You are best recommended to use the provided context(retrieved documents) for your responses \n",
    "    unless you need extra resources outside for more comprehensive or insightful advice.\n",
    "    You should be concise and professional.\n",
    "    \n",
    "    Make sure to format headings and sub headings in bold and approppriate heading element for each in your markdown responses:\n",
    "    example: heading and sub headings in **bold** and H2/H3/H4 in an appropriate format.\n",
    "    \n",
    "    Below is the context: \n",
    "    <context>\n",
    "    {context}\n",
    "    <context>\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_template),\n",
    "        ('human', \"{question}\")\n",
    "    ])\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cacef81-0841-4151-953d-d8729ac25504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain_rag_elements(vector_store, prompt): \n",
    "    # Chat Models: https://python.langchain.com/docs/integrations/chat/ \n",
    "    llm = ChatOpenAI(model=OPENAI_MODEL_ID, streaming=True)\n",
    "    retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "    parser = StrOutputParser() \n",
    "\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt \n",
    "        | llm\n",
    "        | parser\n",
    "    )\n",
    "    \n",
    "    return rag_chain\n",
    "\n",
    "\n",
    "# query = \"What is SEO?\" \n",
    "# chain = chain_rag_elements()\n",
    "\n",
    "# for chunk in chain.stream(query): \n",
    "    # print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323aefef-7252-4240-9edd-141462a9f449",
   "metadata": {},
   "source": [
    "## Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45c52234-7b02-4957-8859-dfc1987f9535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rag_workflow(embeddings=OpenAIEmbeddings(api_key=OPENAI_API_KEY)): \n",
    "    ### Instantiate vector store that vectorizes text \n",
    "    ### from Google Docs(as the externa resource for RAG vector store)\n",
    "    if os.path.exists(db_path) and os.listdir(path=db_path): \n",
    "        print(\"Loading existing vertor store...\")\n",
    "        vector_db = Chroma(\n",
    "            persist_directory=db_path, \n",
    "            embedding_function=embeddings\n",
    "        )\n",
    "    else: \n",
    "         vector_db = vectorize_text()\n",
    "    # print(vector_store._collection.count())\n",
    "\n",
    "    ### Chain all necessary elements into the RAG chain\n",
    "    template = get_prompt()\n",
    "    rag_chain = chain_rag_elements(vector_db, template)\n",
    "\n",
    "    return rag_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fece21-66ef-4f76-8685-6b88b7c80bfd",
   "metadata": {},
   "source": [
    "## UI (Gradio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6468e24c-5bc4-4f66-80b7-24fa06ecc163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/VTG/Dev/C_5/Projects/week5/Project-rag with google drive/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9556f71-4161-44e9-89a8-ffb58f5d3aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing vertor store...\n"
     ]
    }
   ],
   "source": [
    "chain = build_rag_workflow()\n",
    "\n",
    "def chat(query, history): \n",
    "    response = \"\"\n",
    "    for chunk in chain.stream(query):\n",
    "        response += chunk\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7b13035-c048-4b44-b9b7-caa79b3d9a58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "demo = gr.ChatInterface(fn=chat, type=\"messages\", title=\"SEO Expert Bot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba2d2165-dc86-45a2-b0d9-46a8f423ecab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79798a0-d589-46e9-b39d-ba6f0957d7fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
